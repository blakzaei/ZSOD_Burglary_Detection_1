{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3670114,"sourceType":"datasetVersion","datasetId":1704076}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython import display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:22:53.746797Z","iopub.execute_input":"2024-12-31T09:22:53.747024Z","iopub.status.idle":"2024-12-31T09:22:53.756165Z","shell.execute_reply.started":"2024-12-31T09:22:53.746996Z","shell.execute_reply":"2024-12-31T09:22:53.755005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install timm transformers torchvision\n\ndisplay.clear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T06:00:59.300173Z","iopub.execute_input":"2024-12-29T06:00:59.300566Z","iopub.status.idle":"2024-12-29T06:01:08.042426Z","shell.execute_reply.started":"2024-12-29T06:00:59.300540Z","shell.execute_reply":"2024-12-29T06:01:08.041317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Import -----------------------------------------------------------------------------------------------\nimport cv2\nimport torch\nimport timm\nfrom torchvision import transforms\nfrom transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\nfrom typing import List\nimport os\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-12-31T09:22:57.089184Z","iopub.execute_input":"2024-12-31T09:22:57.089494Z","iopub.status.idle":"2024-12-31T09:23:08.904264Z","shell.execute_reply.started":"2024-12-31T09:22:57.089471Z","shell.execute_reply":"2024-12-31T09:23:08.903370Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nintput_path = '/kaggle/input/'\nout_path = '/kaggle/working/'\n\nresult_video_dir = out_path + 'result_videos/'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:' , DEVICE)\n\nDINO_BOX_THRESHOLD = 0.25\nDINO_TEXT_THRESHOLD = 0.1\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-12-31T09:23:11.654140Z","iopub.execute_input":"2024-12-31T09:23:11.654743Z","iopub.status.idle":"2024-12-31T09:23:11.715534Z","shell.execute_reply.started":"2024-12-31T09:23:11.654711Z","shell.execute_reply":"2024-12-31T09:23:11.714630Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(result_video_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:13.780333Z","iopub.execute_input":"2024-12-31T09:23:13.780663Z","iopub.status.idle":"2024-12-31T09:23:13.785291Z","shell.execute_reply.started":"2024-12-31T09:23:13.780638Z","shell.execute_reply":"2024-12-31T09:23:13.784197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dino_model = timm.create_model(\"vit_base_patch16_224_dino\", pretrained=True)\ndino_model.eval()\n\nclip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n\ndisplay.clear_output()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:15.200107Z","iopub.execute_input":"2024-12-31T09:23:15.200713Z","iopub.status.idle":"2024-12-31T09:23:52.282074Z","shell.execute_reply.started":"2024-12-31T09:23:15.200685Z","shell.execute_reply":"2024-12-31T09:23:52.281085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Set labels for ZSOD Models ------------------------------------------------------------------------------------\nlabels = [\n    \"Person climbing over a fence\",\n    \"Person climbing a wall\",\n    \"Person breaking a lock with tools\",\n    \"Person trying to pick a lock\",\n    \"Person forcing a door open with strength\",\n    \"Person peeking through a window\",\n    #\"Person carrying stolen items\",\n    \"Person sneaking into a building\",\n    \"Person looking around nervously\",\n    #\"Person hiding behind an object\",\n    \"Person running away from a building\",\n    \"Person carrying tools like a crowbar\",\n    \"Person breaking a window with an object\",\n    \"Person tampering with a security camera\",\n    \"Person cutting alarm wires\",\n    #\"Person jumping over a barrier\",\n    #\"Person carrying a large bag suspiciously\",\n    \"Person entering a restricted area\",\n    #\"Person hiding stolen items in a bag\",\n    \"Person fighting with a security guard\",\n    #\"Person avoiding eye contact with others\",\n    \"Person loitering near a building\",\n    \"Person jumping out of a window\",\n    \"Person disabling an alarm system\",\n    \"Person wearing a mask and avoiding detection\"\n] \n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-12-31T09:23:54.793879Z","iopub.execute_input":"2024-12-31T09:23:54.794533Z","iopub.status.idle":"2024-12-31T09:23:54.799355Z","shell.execute_reply.started":"2024-12-31T09:23:54.794504Z","shell.execute_reply":"2024-12-31T09:23:54.798387Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(frame):\n    preprocess = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    ])\n    return preprocess(frame).unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:57.114323Z","iopub.execute_input":"2024-12-31T09:23:57.115074Z","iopub.status.idle":"2024-12-31T09:23:57.119935Z","shell.execute_reply.started":"2024-12-31T09:23:57.115045Z","shell.execute_reply":"2024-12-31T09:23:57.118985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_image_features_dino(frame):\n    with torch.no_grad():\n        frame_tensor = preprocess_image(frame)\n        features = dino_model.forward_features(frame_tensor)\n        return features.mean(dim=1)  # Average pooling","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:58.770304Z","iopub.execute_input":"2024-12-31T09:23:58.770773Z","iopub.status.idle":"2024-12-31T09:23:58.775458Z","shell.execute_reply.started":"2024-12-31T09:23:58.770736Z","shell.execute_reply":"2024-12-31T09:23:58.774474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_features_clip(labels: List[str]):\n    inputs = clip_processor(text=labels, return_tensors=\"pt\", padding=True)\n    with torch.no_grad():\n        text_features = clip_model.get_text_features(**inputs)\n    return text_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:24:00.577950Z","iopub.execute_input":"2024-12-31T09:24:00.578840Z","iopub.status.idle":"2024-12-31T09:24:00.583950Z","shell.execute_reply.started":"2024-12-31T09:24:00.578804Z","shell.execute_reply":"2024-12-31T09:24:00.582943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def process_video(video_path, labels, frame_skip=30):\n#     # استخراج بردارهای متنی\n#     text_features = extract_text_features_clip(labels)\n\n#     # باز کردن ویدیو\n#     cap = cv2.VideoCapture(video_path)\n#     frame_count = 0\n#     results = []\n\n    \n    \n#     while cap.isOpened():\n#         ret, frame = cap.read()\n#         if not ret:\n#             break\n\n\n#         # پردازش هر frame_skip‌ام فریم\n#         if frame_count % frame_skip == 0:\n#             # تبدیل فریم به فرمت PIL\n#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n#             frame_pil = Image.fromarray(frame)\n\n#             # استخراج ویژگی‌های تصویری\n#             image_features = extract_image_features_dino(frame_pil)\n\n#             # محاسبه شباهت کسینوسی\n#             similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n#             top_label_idx = torch.argmax(similarities).item()\n#             results.append((frame_count, labels[top_label_idx], similarities[top_label_idx].item()))\n\n#         frame_count += 1\n\n#     cap.release()\n#     return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T06:20:45.519215Z","iopub.execute_input":"2024-12-29T06:20:45.520199Z","iopub.status.idle":"2024-12-29T06:20:45.526758Z","shell.execute_reply.started":"2024-12-29T06:20:45.520167Z","shell.execute_reply":"2024-12-29T06:20:45.525835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_video(video_path, labels, frame_skip=30):\n    # استخراج بردارهای متنی\n    text_features = extract_text_features_clip(labels)\n\n    # باز کردن ویدیو\n    cap = cv2.VideoCapture(video_path)\n    frame_count = 0\n    results = []\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # پردازش هر frame_skip‌ام فریم\n        if frame_count % frame_skip == 0:\n            # تبدیل فریم به فرمت PIL\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frame_pil = Image.fromarray(frame)\n\n            # استخراج ویژگی‌های تصویری\n            image_features = extract_image_features_dino(frame_pil)\n\n            # محاسبه شباهت کسینوسی\n            similarities = torch.nn.functional.cosine_similarity(image_features, text_features)\n\n            # یافتن سه شباهت برتر\n            topk_similarities, topk_indices = torch.topk(similarities, k=3)\n            topk_labels = [labels[idx] for idx in topk_indices]\n\n            # ذخیره نتایج\n            results.append((frame_count, topk_labels, topk_similarities.tolist()))\n\n        frame_count += 1\n\n    cap.release()\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:24:03.973352Z","iopub.execute_input":"2024-12-31T09:24:03.973682Z","iopub.status.idle":"2024-12-31T09:24:03.980171Z","shell.execute_reply.started":"2024-12-31T09:24:03.973658Z","shell.execute_reply":"2024-12-31T09:24:03.979397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"burglary_samples_dir = '/kaggle/input/anomalydetectiondatasetucf/Burglary/'\nnormal_samples_dir = '/kaggle/input/anomalydetectiondatasetucf/Normal_Videos_for_Event_Recognition/Normal_Videos_for_Event_Recognition/'","metadata":{"execution":{"iopub.status.busy":"2024-12-31T09:24:07.112890Z","iopub.execute_input":"2024-12-31T09:24:07.113474Z","iopub.status.idle":"2024-12-31T09:24:07.117353Z","shell.execute_reply.started":"2024-12-31T09:24:07.113445Z","shell.execute_reply":"2024-12-31T09:24:07.116505Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfor video_file in os.listdir(burglary_samples_dir):    \n    #-- log --\n    print(f'Processing {video_file} ==========================================================') \n\n    if video_file != 'Burglary081_x264A.mp4':\n        continue\n\n    video_path = os.path.join(burglary_samples_dir, video_file)        \n    results = process_video(video_path, labels, frame_skip=30)\n    \n    # # 8. نمایش نتایج\n    # for frame_idx, label, similarity in results:\n    #     print(f\"Frame {frame_idx}: Predicted label = {label} (Similarity = {similarity:.4f})\")\n\n    for frame_idx, top_labels, similarities in results:\n        print(f\"Frame {frame_idx}:\")\n        for label, similarity in zip(top_labels, similarities):\n            print(f\"    {label} (Similarity = {similarity:.4f})\")\n\n\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:25:45.435606Z","iopub.execute_input":"2024-12-31T09:25:45.435927Z","iopub.status.idle":"2024-12-31T09:25:48.442951Z","shell.execute_reply.started":"2024-12-31T09:25:45.435905Z","shell.execute_reply":"2024-12-31T09:25:48.442017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfor video_file in os.listdir(normal_samples_dir):    \n    #-- log --\n    print(f'Processing {video_file} ==========================================================') \n\n    if video_file != 'Normal_Videos_129_x264.mp4':\n        continue\n\n    video_path = os.path.join(normal_samples_dir, video_file)        \n    results = process_video(video_path, labels, frame_skip=30)\n    \n    # # 8. نمایش نتایج\n    # for frame_idx, label, similarity in results:\n    #     print(f\"Frame {frame_idx}: Predicted label = {label} (Similarity = {similarity:.4f})\")\n\n    \n    for frame_idx, top_labels, similarities in results:\n        print(f\"Frame {frame_idx}:\")\n        for label, similarity in zip(top_labels, similarities):\n            print(f\"    {label} (Similarity = {similarity:.4f})\")\n\n\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:29:12.762339Z","iopub.execute_input":"2024-12-31T09:29:12.763150Z","iopub.status.idle":"2024-12-31T09:29:16.308054Z","shell.execute_reply.started":"2024-12-31T09:29:12.763121Z","shell.execute_reply":"2024-12-31T09:29:16.307012Z"}},"outputs":[],"execution_count":null}]}